{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7714a198",
   "metadata": {},
   "source": [
    "### Model Exercises\n",
    "\n",
    "Do your work for this exercise in a file named `model`.\n",
    "\n",
    "Take the work we did in the lessons further:\n",
    "\n",
    "- What other types of models (i.e. different classifcation algorithms) could you use?\n",
    "- How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17aeda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import prepare\n",
    "\n",
    "from prepare import basic_clean, lemmatize\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from env import user, password, host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "edb23c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "id                                                         \n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_db_url(database, host=host, user=user, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "url = get_db_url(\"spam_db\")\n",
    "sql = \"SELECT * FROM spam\"\n",
    "\n",
    "df = pd.read_sql(sql, url, index_col=\"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e5aee",
   "metadata": {},
   "source": [
    "#### Logistic Regression - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a32197",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d32d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.37%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   115\n",
      "spam          2   483\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.81      0.89       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.90      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a45551c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.86%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        965    34\n",
      "spam         1   115\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       966\n",
      "        spam       0.99      0.77      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2fd00",
   "metadata": {},
   "source": [
    "#### Logistic Regression - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea483349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_bag_of_words = cv.fit_transform(df.text)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e8bd83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fdbefbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000pes',\n",
       " '008704050406',\n",
       " '0089',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '0125698789',\n",
       " '02',\n",
       " '0207',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '021',\n",
       " '03',\n",
       " '04',\n",
       " '0430',\n",
       " '05',\n",
       " '050703',\n",
       " '0578',\n",
       " '06',\n",
       " '07',\n",
       " '07008009200',\n",
       " '07046744435',\n",
       " '07090201529',\n",
       " '07090298926',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '0721072',\n",
       " '07732584351',\n",
       " '07734396839',\n",
       " '07742676969',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07781482378',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '078',\n",
       " '07801543489',\n",
       " '07808',\n",
       " '07808247860',\n",
       " '07808726822',\n",
       " '07815296484',\n",
       " '07821230901',\n",
       " '078498',\n",
       " '07880867867',\n",
       " '0789xxxxxxx',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '08000407165',\n",
       " '08000776320',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08002988890',\n",
       " '08006344447',\n",
       " '0808',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0825',\n",
       " '083',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845',\n",
       " '08450542832',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075over18',\n",
       " '0870',\n",
       " '08700435505150p',\n",
       " '08700469649',\n",
       " '08700621170150p',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701417012150p',\n",
       " '0870141701216',\n",
       " '087016248',\n",
       " '08701752560',\n",
       " '087018728737',\n",
       " '0870241182716',\n",
       " '08702490080',\n",
       " '08702840625',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08704439680ts',\n",
       " '08706091795',\n",
       " '0870737910216yrs',\n",
       " '08707500020',\n",
       " '08707509020',\n",
       " '0870753331018',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '08709501522',\n",
       " '0871',\n",
       " '087104711148',\n",
       " '08712101358',\n",
       " '08712103738',\n",
       " '0871212025016',\n",
       " '08712300220',\n",
       " '087123002209am',\n",
       " '08712317606',\n",
       " '08712400200',\n",
       " '08712400602450p',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712402972',\n",
       " '08712404000',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '08712466669',\n",
       " '0871277810710p',\n",
       " '0871277810810',\n",
       " '0871277810910p',\n",
       " '08714342399',\n",
       " '087147123779am',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714712394',\n",
       " '08714712412',\n",
       " '08714714011',\n",
       " '08715203028',\n",
       " '08715203649',\n",
       " '08715203652',\n",
       " '08715203656',\n",
       " '08715203677',\n",
       " '08715203685',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '08717168528',\n",
       " '08717205546',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717509990',\n",
       " '08717890890å',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718723815',\n",
       " '08718725756',\n",
       " '08718726270',\n",
       " '087187262701',\n",
       " '08718726970',\n",
       " '08718726971',\n",
       " '08718726978',\n",
       " '087187272008',\n",
       " '08718727868',\n",
       " '08718727870',\n",
       " '08718727870150ppm',\n",
       " '08718730555',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08718738034',\n",
       " '08719180219',\n",
       " '08719180248',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719181513',\n",
       " '08719839835',\n",
       " '08719899217',\n",
       " '08719899229',\n",
       " '08719899230',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000332',\n",
       " '09050000460',\n",
       " '09050000555',\n",
       " '09050000878',\n",
       " '09050000928',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050002311',\n",
       " '09050003091',\n",
       " '09050005321',\n",
       " '09050090044',\n",
       " '09050280520',\n",
       " '09053750005',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058091870',\n",
       " '09058094454',\n",
       " '09058094455',\n",
       " '09058094507',\n",
       " '09058094565',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058094599',\n",
       " '09058095107',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061701461',\n",
       " '09061701851',\n",
       " '09061701939',\n",
       " '09061702893',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061743811',\n",
       " '09061744553',\n",
       " '09061749602',\n",
       " '09061790121',\n",
       " '09061790125',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '0906346330',\n",
       " '09064011000',\n",
       " '09064012103',\n",
       " '09064012160',\n",
       " '09064015307',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09064019788',\n",
       " '09065069120',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065394514',\n",
       " '09065394973',\n",
       " '09065989180',\n",
       " '09065989182',\n",
       " '09066350750',\n",
       " '09066358152',\n",
       " '09066358361',\n",
       " '09066361921',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364349',\n",
       " '09066364589',\n",
       " '09066368327',\n",
       " '09066368470',\n",
       " '09066368753',\n",
       " '09066380611',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066649731from',\n",
       " '09066660100',\n",
       " '09071512432',\n",
       " '09071512433',\n",
       " '09071517866',\n",
       " '09077818151',\n",
       " '09090204448',\n",
       " '09090900040',\n",
       " '09094100151',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09095350301',\n",
       " '09096102316',\n",
       " '09099725823',\n",
       " '09099726395',\n",
       " '09099726429',\n",
       " '09099726481',\n",
       " '09099726553',\n",
       " '09111030116',\n",
       " '09111032124',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '0quit',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000call',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100percent',\n",
       " '100txt',\n",
       " '1013',\n",
       " '1030',\n",
       " '10am',\n",
       " '10k',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '10th',\n",
       " '11',\n",
       " '1120',\n",
       " '113',\n",
       " '1131',\n",
       " '114',\n",
       " '116',\n",
       " '1172',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '1205',\n",
       " '120p',\n",
       " '121',\n",
       " '1225',\n",
       " '123',\n",
       " '125',\n",
       " '1250',\n",
       " '125gift',\n",
       " '128',\n",
       " '12hours',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '13',\n",
       " '130',\n",
       " '1327',\n",
       " '139',\n",
       " '14',\n",
       " '140',\n",
       " '1405',\n",
       " '140ppm',\n",
       " '145',\n",
       " '1450',\n",
       " '146tf150p',\n",
       " '14tcr',\n",
       " '14thmarch',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmpobox10183bhamb64xe',\n",
       " '150ppmsg',\n",
       " '150pw',\n",
       " '151',\n",
       " '153',\n",
       " '15541',\n",
       " '15pm',\n",
       " '16',\n",
       " '165',\n",
       " '1680',\n",
       " '169',\n",
       " '177',\n",
       " '18',\n",
       " '180',\n",
       " '1843',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '195',\n",
       " '1956669',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1da',\n",
       " '1er',\n",
       " '1hr',\n",
       " '1im',\n",
       " '1lemon',\n",
       " '1mega',\n",
       " '1million',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice',\n",
       " '1stone',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '1yf',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '200p',\n",
       " '2025050',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21870000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '2309',\n",
       " '23f',\n",
       " '23g',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26',\n",
       " '2667',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '2814032',\n",
       " '28days',\n",
       " '28th',\n",
       " '28thfeb',\n",
       " '29',\n",
       " '2b',\n",
       " '2bold',\n",
       " '2c',\n",
       " '2channel',\n",
       " '2day',\n",
       " '2end',\n",
       " '2exit',\n",
       " '2ez',\n",
       " '2find',\n",
       " '2getha',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2gthr',\n",
       " '2hrs',\n",
       " '2kbsubject',\n",
       " '2lands',\n",
       " '2marrow',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mro',\n",
       " '2mrw',\n",
       " '2nd',\n",
       " '2nhite',\n",
       " '2nights',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2price',\n",
       " '2px',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2u',\n",
       " '2u2',\n",
       " '2waxsto',\n",
       " '2wks',\n",
       " '2wt',\n",
       " '2wu',\n",
       " '2years',\n",
       " '2yr',\n",
       " '2yrs',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300603t',\n",
       " '300p',\n",
       " '3030',\n",
       " '30apr',\n",
       " '30ish',\n",
       " '30pm',\n",
       " '30pp',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '3100',\n",
       " '310303',\n",
       " '31p',\n",
       " '32',\n",
       " '32000',\n",
       " '3230',\n",
       " '32323',\n",
       " '326',\n",
       " '33',\n",
       " '330',\n",
       " '350',\n",
       " '3510i',\n",
       " '35p',\n",
       " '3650',\n",
       " '36504',\n",
       " '3680',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '38',\n",
       " '382',\n",
       " '391784',\n",
       " '3aj',\n",
       " '3d',\n",
       " '3days',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lions',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3wks',\n",
       " '3xx',\n",
       " '3xå',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '400thousad',\n",
       " '402',\n",
       " '4041',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '40mph',\n",
       " '41685',\n",
       " '41782',\n",
       " '420',\n",
       " '42049',\n",
       " '4217',\n",
       " '42478',\n",
       " '42810',\n",
       " '430',\n",
       " '434',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '44345',\n",
       " '447797706009',\n",
       " '447801259231',\n",
       " '448712404000',\n",
       " '449050000301',\n",
       " '449071512431',\n",
       " '45',\n",
       " '450',\n",
       " '450p',\n",
       " '450pw',\n",
       " '45239',\n",
       " '45pm',\n",
       " '47',\n",
       " '4719',\n",
       " '4742',\n",
       " '47per',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49',\n",
       " '49557',\n",
       " '4a',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4few',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4give',\n",
       " '4got',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4msgs',\n",
       " '4mths',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4the',\n",
       " '4thnov',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4utxt',\n",
       " '4w',\n",
       " '4ward',\n",
       " '4wrd',\n",
       " '4xx26',\n",
       " '4years',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '505060',\n",
       " '50award',\n",
       " '50ea',\n",
       " '50gbp',\n",
       " '50p',\n",
       " '50perweeksub',\n",
       " '50perwksub',\n",
       " '50pm',\n",
       " '50pmmorefrommobile2bremoved',\n",
       " '50ppm',\n",
       " '50rcvd',\n",
       " '50s',\n",
       " '515',\n",
       " '5226',\n",
       " '523',\n",
       " '526',\n",
       " '528',\n",
       " '530',\n",
       " '54',\n",
       " '542',\n",
       " '545',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5ish',\n",
       " '5k',\n",
       " '5min',\n",
       " '5mls',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '5wq',\n",
       " '5years',\n",
       " '60',\n",
       " '600',\n",
       " '6031',\n",
       " '6089',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '62220cncl',\n",
       " '6230',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '63miles',\n",
       " '645',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '6669',\n",
       " '674',\n",
       " '67441233',\n",
       " '68866',\n",
       " '69101',\n",
       " '69200',\n",
       " '69669',\n",
       " '69696',\n",
       " '69698',\n",
       " '69855',\n",
       " '69866',\n",
       " '69876',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '69969',\n",
       " '69988',\n",
       " '6days',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6times',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '700',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '730',\n",
       " '731',\n",
       " '74355',\n",
       " '75',\n",
       " '750',\n",
       " '7548',\n",
       " '75max',\n",
       " '762',\n",
       " '7634',\n",
       " '7684',\n",
       " '77',\n",
       " '7732584351',\n",
       " '78',\n",
       " '786',\n",
       " '7876150ppm',\n",
       " '79',\n",
       " '7am',\n",
       " '7cfca1a',\n",
       " '7ish',\n",
       " '7mp',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '7ws',\n",
       " '7zs',\n",
       " '80',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80086',\n",
       " '80122300p',\n",
       " '80155',\n",
       " '80160',\n",
       " '80182',\n",
       " '8027',\n",
       " '80488',\n",
       " '80608',\n",
       " '8077',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '81618',\n",
       " '82050',\n",
       " '820554ad0a1705572711',\n",
       " '82242',\n",
       " '82277',\n",
       " '82324',\n",
       " '82468',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83110',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332',\n",
       " '83338',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84',\n",
       " '84025',\n",
       " '84122',\n",
       " '84128',\n",
       " '84199',\n",
       " '84484',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '85069',\n",
       " '85222',\n",
       " '85233',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '864233',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '8714714',\n",
       " '872',\n",
       " '87239',\n",
       " '87575',\n",
       " '8800',\n",
       " '88039',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88877',\n",
       " '88888',\n",
       " '89034',\n",
       " '89070',\n",
       " '89080',\n",
       " '89105',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '89938',\n",
       " '8am',\n",
       " '8ball',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8wp',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9153',\n",
       " '9280114',\n",
       " '930',\n",
       " '9307622',\n",
       " '945',\n",
       " '946',\n",
       " '95',\n",
       " '9755',\n",
       " '9758',\n",
       " '97n7qp',\n",
       " '98321561',\n",
       " '99',\n",
       " '9996',\n",
       " '9ae',\n",
       " '9am',\n",
       " '9ja',\n",
       " '9pm',\n",
       " '9t',\n",
       " '9th',\n",
       " '9yt',\n",
       " '____',\n",
       " 'a21',\n",
       " 'a30',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aaniye',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'ab',\n",
       " 'abbey',\n",
       " 'abdomen',\n",
       " 'abeg',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'about',\n",
       " 'aboutas',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abuse',\n",
       " 'abusers',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accenture',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accidant',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodation',\n",
       " 'accommodationvouchers',\n",
       " 'accomodate',\n",
       " 'accomodations',\n",
       " 'accordin',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulation',\n",
       " 'achan',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'acid',\n",
       " 'acknowledgement',\n",
       " 'acl03530150pm',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activ8',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addie',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adewale',\n",
       " 'adi',\n",
       " 'adjustable',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'adore',\n",
       " 'adoring',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'adventuring',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advising',\n",
       " 'advisors',\n",
       " 'aeronautics',\n",
       " 'aeroplane',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affections',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterwards',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'age16',\n",
       " 'age23',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'agidhane',\n",
       " 'aging',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aid',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'air1',\n",
       " 'airport',\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c8e866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 3550,\n",
       " 'until': 8030,\n",
       " 'jurong': 4350,\n",
       " 'point': 5920,\n",
       " 'crazy': 2327,\n",
       " 'available': 1303,\n",
       " 'only': 5537,\n",
       " 'in': 4087,\n",
       " 'bugis': 1751,\n",
       " 'great': 3634,\n",
       " 'world': 8489,\n",
       " 'la': 4476,\n",
       " 'buffet': 1749,\n",
       " 'cine': 2048,\n",
       " 'there': 7645,\n",
       " 'got': 3594,\n",
       " 'amore': 1069,\n",
       " 'wat': 8267,\n",
       " 'ok': 5504,\n",
       " 'lar': 4512,\n",
       " 'joking': 4318,\n",
       " 'wif': 8392,\n",
       " 'oni': 5533,\n",
       " 'free': 3358,\n",
       " 'entry': 2949,\n",
       " 'wkly': 8447,\n",
       " 'comp': 2165,\n",
       " 'to': 7756,\n",
       " 'win': 8405,\n",
       " 'fa': 3087,\n",
       " 'cup': 2386,\n",
       " 'final': 3207,\n",
       " 'tkts': 7743,\n",
       " '21st': 411,\n",
       " 'may': 4930,\n",
       " '2005': 402,\n",
       " 'text': 7595,\n",
       " '87121': 784,\n",
       " 'receive': 6297,\n",
       " 'question': 6190,\n",
       " 'std': 7230,\n",
       " 'txt': 7933,\n",
       " 'rate': 6242,\n",
       " 'apply': 1156,\n",
       " '08452810075over18': 77,\n",
       " 'dun': 2802,\n",
       " 'say': 6633,\n",
       " 'so': 7024,\n",
       " 'early': 2823,\n",
       " 'hor': 3927,\n",
       " 'already': 1042,\n",
       " 'then': 7640,\n",
       " 'nah': 5238,\n",
       " 'don': 2712,\n",
       " 'think': 7660,\n",
       " 'he': 3781,\n",
       " 'goes': 3558,\n",
       " 'usf': 8075,\n",
       " 'lives': 4665,\n",
       " 'around': 1207,\n",
       " 'here': 3831,\n",
       " 'though': 7680,\n",
       " 'freemsg': 3365,\n",
       " 'hey': 3841,\n",
       " 'darling': 2443,\n",
       " 'it': 4218,\n",
       " 'been': 1460,\n",
       " 'week': 8313,\n",
       " 'now': 5420,\n",
       " 'and': 1084,\n",
       " 'no': 5367,\n",
       " 'word': 8480,\n",
       " 'back': 1351,\n",
       " 'like': 4615,\n",
       " 'some': 7039,\n",
       " 'fun': 3419,\n",
       " 'you': 8609,\n",
       " 'up': 8032,\n",
       " 'for': 3308,\n",
       " 'still': 7253,\n",
       " 'tb': 7529,\n",
       " 'xxx': 8555,\n",
       " 'chgs': 2002,\n",
       " 'send': 6723,\n",
       " '50': 607,\n",
       " 'rcv': 6255,\n",
       " 'even': 2998,\n",
       " 'my': 5223,\n",
       " 'brother': 1722,\n",
       " 'is': 4206,\n",
       " 'not': 5405,\n",
       " 'speak': 7112,\n",
       " 'with': 8433,\n",
       " 'me': 4939,\n",
       " 'they': 7653,\n",
       " 'treat': 7863,\n",
       " 'aids': 992,\n",
       " 'patent': 5722,\n",
       " 'as': 1224,\n",
       " 'per': 5764,\n",
       " 'your': 8615,\n",
       " 'request': 6406,\n",
       " 'melle': 4969,\n",
       " 'oru': 5593,\n",
       " 'minnaminunginte': 5036,\n",
       " 'nurungu': 5440,\n",
       " 'vettam': 8131,\n",
       " 'has': 3757,\n",
       " 'set': 6750,\n",
       " 'callertune': 1823,\n",
       " 'all': 1029,\n",
       " 'callers': 1822,\n",
       " 'press': 6041,\n",
       " 'copy': 2266,\n",
       " 'friends': 3381,\n",
       " 'winner': 8416,\n",
       " 'valued': 8100,\n",
       " 'network': 5317,\n",
       " 'customer': 2399,\n",
       " 'have': 3770,\n",
       " 'selected': 6709,\n",
       " 'receivea': 6298,\n",
       " '900': 816,\n",
       " 'prize': 6073,\n",
       " 'reward': 6461,\n",
       " 'claim': 2054,\n",
       " 'call': 1813,\n",
       " '09061701461': 224,\n",
       " 'code': 2120,\n",
       " 'kl341': 4439,\n",
       " 'valid': 8096,\n",
       " '12': 322,\n",
       " 'hours': 3947,\n",
       " 'had': 3699,\n",
       " 'mobile': 5089,\n",
       " '11': 312,\n",
       " 'months': 5129,\n",
       " 'or': 5570,\n",
       " 'more': 5133,\n",
       " 'entitled': 2946,\n",
       " 'update': 8037,\n",
       " 'the': 7627,\n",
       " 'latest': 4526,\n",
       " 'colour': 2141,\n",
       " 'mobiles': 5090,\n",
       " 'camera': 1835,\n",
       " 'co': 2109,\n",
       " 'on': 5525,\n",
       " '08002986030': 61,\n",
       " 'gonna': 3574,\n",
       " 'be': 1438,\n",
       " 'home': 3901,\n",
       " 'soon': 7066,\n",
       " 'want': 8245,\n",
       " 'talk': 7496,\n",
       " 'about': 859,\n",
       " 'this': 7669,\n",
       " 'stuff': 7320,\n",
       " 'anymore': 1123,\n",
       " 'tonight': 7792,\n",
       " 've': 8115,\n",
       " 'cried': 2344,\n",
       " 'enough': 2936,\n",
       " 'today': 7763,\n",
       " 'six': 6928,\n",
       " 'chances': 1943,\n",
       " 'cash': 1889,\n",
       " 'from': 3397,\n",
       " '100': 298,\n",
       " '20': 397,\n",
       " '000': 1,\n",
       " 'pounds': 5982,\n",
       " 'csh11': 2363,\n",
       " '87575': 789,\n",
       " 'cost': 2278,\n",
       " '150p': 351,\n",
       " 'day': 2458,\n",
       " '6days': 680,\n",
       " '16': 363,\n",
       " 'tsandcs': 7898,\n",
       " 'reply': 6399,\n",
       " 'hl': 3873,\n",
       " 'info': 4122,\n",
       " 'urgent': 8055,\n",
       " 'won': 8464,\n",
       " 'membership': 4975,\n",
       " 'our': 5606,\n",
       " 'jackpot': 4247,\n",
       " '81010': 737,\n",
       " 'www': 8537,\n",
       " 'dbuk': 2463,\n",
       " 'net': 5311,\n",
       " 'lccltd': 4543,\n",
       " 'pobox': 5899,\n",
       " '4403ldnw1a7rw18': 559,\n",
       " 'searching': 6678,\n",
       " 'right': 6473,\n",
       " 'words': 8481,\n",
       " 'thank': 7612,\n",
       " 'breather': 1691,\n",
       " 'promise': 6105,\n",
       " 'wont': 8471,\n",
       " 'take': 7488,\n",
       " 'help': 3817,\n",
       " 'granted': 3623,\n",
       " 'will': 8402,\n",
       " 'fulfil': 3415,\n",
       " 'wonderful': 8468,\n",
       " 'blessing': 1567,\n",
       " 'at': 1260,\n",
       " 'times': 7722,\n",
       " 'date': 2451,\n",
       " 'sunday': 7388,\n",
       " 'xxxmobilemovieclub': 8556,\n",
       " 'use': 8069,\n",
       " 'credit': 2334,\n",
       " 'click': 2077,\n",
       " 'wap': 8250,\n",
       " 'link': 4637,\n",
       " 'next': 5334,\n",
       " 'message': 4993,\n",
       " 'http': 3968,\n",
       " 'com': 2144,\n",
       " 'qjkgighjjgcbl': 6182,\n",
       " 'oh': 5499,\n",
       " 'watching': 8272,\n",
       " 'eh': 2870,\n",
       " 'remember': 6366,\n",
       " 'how': 3953,\n",
       " 'spell': 7127,\n",
       " 'his': 3864,\n",
       " 'name': 5244,\n",
       " 'yes': 8592,\n",
       " 'did': 2592,\n",
       " 'naughty': 5271,\n",
       " 'make': 4848,\n",
       " 'wet': 8350,\n",
       " 'fine': 3215,\n",
       " 'if': 4041,\n",
       " 'thatåõs': 7625,\n",
       " 'way': 8284,\n",
       " 'feel': 3158,\n",
       " 'its': 4225,\n",
       " 'gota': 3595,\n",
       " 'england': 2927,\n",
       " 'macedonia': 4810,\n",
       " 'dont': 2716,\n",
       " 'miss': 5052,\n",
       " 'goals': 3554,\n",
       " 'team': 7541,\n",
       " 'news': 5330,\n",
       " 'ur': 8051,\n",
       " 'national': 5265,\n",
       " '87077': 783,\n",
       " 'eg': 2865,\n",
       " 'try': 7894,\n",
       " 'wales': 8225,\n",
       " 'scotland': 6657,\n",
       " '4txt': 599,\n",
       " 'ì¼1': 8659,\n",
       " 'poboxox36504w45wq': 5911,\n",
       " 'that': 7621,\n",
       " 'seriously': 6743,\n",
       " 'going': 3563,\n",
       " 'ha': 3695,\n",
       " 'ì_': 8658,\n",
       " 'pay': 5734,\n",
       " 'first': 3232,\n",
       " 'when': 8362,\n",
       " 'da': 2416,\n",
       " 'stock': 7256,\n",
       " 'comin': 2155,\n",
       " 'aft': 962,\n",
       " 'finish': 3218,\n",
       " 'lunch': 4776,\n",
       " 'str': 7281,\n",
       " 'down': 2737,\n",
       " 'lor': 4719,\n",
       " 'ard': 1182,\n",
       " 'smth': 7007,\n",
       " 'ffffffffff': 3177,\n",
       " 'alright': 1043,\n",
       " 'can': 1839,\n",
       " 'meet': 4958,\n",
       " 'sooner': 7067,\n",
       " 'just': 4352,\n",
       " 'forced': 3310,\n",
       " 'myself': 5228,\n",
       " 'eat': 2835,\n",
       " 'slice': 6959,\n",
       " 'really': 6280,\n",
       " 'hungry': 3988,\n",
       " 'tho': 7676,\n",
       " 'sucks': 7357,\n",
       " 'mark': 4885,\n",
       " 'getting': 3511,\n",
       " 'worried': 8492,\n",
       " 'knows': 4450,\n",
       " 'sick': 6877,\n",
       " 'turn': 7917,\n",
       " 'pizza': 5854,\n",
       " 'lol': 4696,\n",
       " 'always': 1052,\n",
       " 'convincing': 2254,\n",
       " 'catch': 1899,\n",
       " 'bus': 1771,\n",
       " 'are': 1183,\n",
       " 'frying': 3403,\n",
       " 'an': 1079,\n",
       " 'egg': 2867,\n",
       " 'tea': 7535,\n",
       " 'eating': 2838,\n",
       " 'mom': 5110,\n",
       " 'left': 4566,\n",
       " 'over': 5627,\n",
       " 'dinner': 2624,\n",
       " 'do': 2675,\n",
       " 'love': 4740,\n",
       " 'amp': 1071,\n",
       " 'we': 8289,\n",
       " 're': 6259,\n",
       " 'packing': 5653,\n",
       " 'car': 1861,\n",
       " 'll': 4669,\n",
       " 'let': 4587,\n",
       " 'know': 4447,\n",
       " 'room': 6514,\n",
       " 'ahhh': 987,\n",
       " 'work': 8482,\n",
       " 'vaguely': 8092,\n",
       " 'what': 8355,\n",
       " 'does': 2687,\n",
       " 'wait': 8219,\n",
       " 'clear': 2071,\n",
       " 'were': 8339,\n",
       " 'sure': 7414,\n",
       " 'being': 1478,\n",
       " 'sarcastic': 6613,\n",
       " 'why': 8385,\n",
       " 'doesn': 2689,\n",
       " 'live': 4661,\n",
       " 'us': 8065,\n",
       " 'yeah': 8580,\n",
       " 'was': 8259,\n",
       " 'apologetic': 1143,\n",
       " 'fallen': 3112,\n",
       " 'out': 5609,\n",
       " 'she': 6795,\n",
       " 'actin': 904,\n",
       " 'spoilt': 7154,\n",
       " 'child': 2010,\n",
       " 'caught': 1903,\n",
       " 'till': 7719,\n",
       " 'but': 1778,\n",
       " 'doing': 2702,\n",
       " 'too': 7796,\n",
       " 'badly': 1356,\n",
       " 'cheers': 1986,\n",
       " 'tell': 7559,\n",
       " 'anything': 1129,\n",
       " 'fear': 3150,\n",
       " 'of': 5477,\n",
       " 'fainting': 3104,\n",
       " 'housework': 3951,\n",
       " 'quick': 6193,\n",
       " 'cuppa': 2388,\n",
       " 'thanks': 7613,\n",
       " 'subscription': 7345,\n",
       " 'ringtone': 6482,\n",
       " 'uk': 7963,\n",
       " 'charged': 1955,\n",
       " 'month': 5126,\n",
       " 'please': 5879,\n",
       " 'confirm': 2209,\n",
       " 'by': 1794,\n",
       " 'replying': 6400,\n",
       " 'yup': 8637,\n",
       " 'look': 4707,\n",
       " 'timings': 7726,\n",
       " 'msg': 5168,\n",
       " 'again': 970,\n",
       " 'xuhui': 8551,\n",
       " 'learn': 4556,\n",
       " '2nd': 461,\n",
       " 'her': 3830,\n",
       " 'lesson': 4585,\n",
       " '8am': 809,\n",
       " 'oops': 5548,\n",
       " 'roommate': 6516,\n",
       " 'done': 2714,\n",
       " 'see': 6695,\n",
       " 'letter': 4589,\n",
       " 'decide': 2481,\n",
       " 'hello': 3814,\n",
       " 'saturday': 6625,\n",
       " 'texting': 7603,\n",
       " 'decided': 2482,\n",
       " 'tomo': 7781,\n",
       " 'trying': 7896,\n",
       " 'invite': 4180,\n",
       " 'pls': 5887,\n",
       " 'ahead': 986,\n",
       " 'watts': 8280,\n",
       " 'wanted': 8247,\n",
       " 'weekend': 8315,\n",
       " 'abiola': 855,\n",
       " 'forget': 3316,\n",
       " 'need': 5291,\n",
       " 'crave': 2324,\n",
       " 'most': 5141,\n",
       " 'sweet': 7445,\n",
       " 'arabian': 1179,\n",
       " 'steed': 7237,\n",
       " 'mmmmmm': 5079,\n",
       " 'yummy': 8632,\n",
       " '07732584351': 30,\n",
       " 'rodger': 6504,\n",
       " 'burns': 1768,\n",
       " 'tried': 7872,\n",
       " 'sms': 7002,\n",
       " 'nokia': 5377,\n",
       " 'camcorder': 1833,\n",
       " '08000930705': 57,\n",
       " 'delivery': 2521,\n",
       " 'tomorrow': 7783,\n",
       " 'who': 8378,\n",
       " 'seeing': 6697,\n",
       " 'hope': 3919,\n",
       " 'man': 4858,\n",
       " 'well': 8330,\n",
       " 'endowed': 2917,\n",
       " 'am': 1054,\n",
       " 'lt': 4763,\n",
       " 'gt': 3663,\n",
       " 'inches': 4091,\n",
       " 'calls': 1828,\n",
       " 'messages': 4995,\n",
       " 'missed': 5054,\n",
       " 'didn': 2594,\n",
       " 'get': 3503,\n",
       " 'hep': 3829,\n",
       " 'immunisation': 4070,\n",
       " 'nigeria': 5344,\n",
       " 'fair': 3105,\n",
       " 'hopefully': 3922,\n",
       " 'tyler': 7946,\n",
       " 'could': 2289,\n",
       " 'maybe': 4932,\n",
       " 'ask': 1234,\n",
       " 'bit': 1544,\n",
       " 'stubborn': 7309,\n",
       " 'hospital': 3934,\n",
       " 'kept': 4396,\n",
       " 'telling': 7560,\n",
       " 'weak': 8290,\n",
       " 'sucker': 7355,\n",
       " 'hospitals': 3935,\n",
       " 'suckers': 7356,\n",
       " 'thinked': 7661,\n",
       " 'time': 7721,\n",
       " 'saw': 6632,\n",
       " 'class': 2063,\n",
       " 'gram': 3615,\n",
       " 'usually': 8081,\n",
       " 'runs': 6557,\n",
       " 'half': 3711,\n",
       " 'eighth': 2873,\n",
       " 'smarter': 6982,\n",
       " 'gets': 3507,\n",
       " 'almost': 1038,\n",
       " 'whole': 8379,\n",
       " 'second': 6682,\n",
       " 'fyi': 3435,\n",
       " 'ride': 6472,\n",
       " 'morning': 5137,\n",
       " 'crashing': 2323,\n",
       " 'place': 5856,\n",
       " 'wow': 8508,\n",
       " 'never': 5321,\n",
       " 'realized': 6278,\n",
       " 'embarassed': 2898,\n",
       " 'accomodations': 886,\n",
       " 'thought': 7681,\n",
       " 'liked': 4616,\n",
       " 'since': 6902,\n",
       " 'best': 1498,\n",
       " 'seemed': 6701,\n",
       " 'happy': 3746,\n",
       " 'cave': 1907,\n",
       " 'sorry': 7076,\n",
       " 'give': 3532,\n",
       " 'offered': 5484,\n",
       " 'embarassing': 2899,\n",
       " 'ac': 872,\n",
       " 'sptv': 7176,\n",
       " 'new': 5325,\n",
       " 'jersey': 4288,\n",
       " 'devils': 2573,\n",
       " 'detroit': 2567,\n",
       " 'red': 6320,\n",
       " 'wings': 8414,\n",
       " 'play': 5870,\n",
       " 'ice': 4022,\n",
       " 'hockey': 3886,\n",
       " 'correct': 2271,\n",
       " 'incorrect': 4102,\n",
       " 'end': 2913,\n",
       " 'mallika': 4857,\n",
       " 'sherawat': 6802,\n",
       " 'yesterday': 8594,\n",
       " 'find': 3212,\n",
       " 'url': 8061,\n",
       " 'congrats': 2215,\n",
       " 'year': 8581,\n",
       " 'special': 7114,\n",
       " 'cinema': 2049,\n",
       " 'pass': 5711,\n",
       " 'yours': 8619,\n",
       " '09061209465': 219,\n",
       " 'suprman': 7412,\n",
       " 'matrix3': 4918,\n",
       " 'starwars3': 7218,\n",
       " 'etc': 2986,\n",
       " 'bx420': 1792,\n",
       " 'ip4': 4189,\n",
       " '5we': 641,\n",
       " '150pm': 353,\n",
       " 'later': 4525,\n",
       " 'meeting': 4960,\n",
       " 'where': 8366,\n",
       " 'reached': 6262,\n",
       " 'gauti': 3469,\n",
       " 'sehwag': 6706,\n",
       " 'odi': 5476,\n",
       " 'series': 6741,\n",
       " 'pick': 5826,\n",
       " 'burger': 1763,\n",
       " 'yourself': 8620,\n",
       " 'move': 5154,\n",
       " 'pain': 5660,\n",
       " 'killing': 4421,\n",
       " 'good': 3576,\n",
       " 'joke': 4314,\n",
       " 'girls': 3529,\n",
       " 'situation': 6925,\n",
       " 'seekers': 6698,\n",
       " 'part': 5700,\n",
       " 'checking': 1980,\n",
       " 'iq': 4195,\n",
       " 'roommates': 6517,\n",
       " 'took': 7797,\n",
       " 'forever': 3313,\n",
       " 'come': 2150,\n",
       " 'double': 2730,\n",
       " 'check': 1976,\n",
       " 'hair': 3706,\n",
       " 'dresser': 2760,\n",
       " 'said': 6583,\n",
       " 'wun': 8536,\n",
       " 'cut': 2403,\n",
       " 'short': 6837,\n",
       " 'nice': 5338,\n",
       " 'pleased': 5880,\n",
       " 'advise': 945,\n",
       " 'following': 3291,\n",
       " 'recent': 6301,\n",
       " 'review': 6459,\n",
       " 'mob': 5087,\n",
       " 'awarded': 1320,\n",
       " '1500': 350,\n",
       " 'bonus': 1608,\n",
       " '09066364589': 267,\n",
       " 'song': 7061,\n",
       " 'dedicated': 2492,\n",
       " 'which': 8372,\n",
       " 'dedicate': 2491,\n",
       " 'valuable': 8098,\n",
       " 'frnds': 3389,\n",
       " 'rply': 6533,\n",
       " 'complimentary': 2184,\n",
       " 'trip': 7873,\n",
       " 'eurodisinc': 2992,\n",
       " 'trav': 7855,\n",
       " 'aco': 900,\n",
       " 'entry41': 2950,\n",
       " '1000': 299,\n",
       " 'dis': 2636,\n",
       " '18': 368,\n",
       " 'morefrmmob': 5134,\n",
       " 'shracomorsglsuplt': 6862,\n",
       " '10': 297,\n",
       " 'ls1': 4759,\n",
       " '3aj': 518,\n",
       " 'hear': 3793,\n",
       " 'divorce': 2665,\n",
       " 'barbie': 1387,\n",
       " 'comes': 2152,\n",
       " 'ken': 4394,\n",
       " 'plane': 5862,\n",
       " 'wah': 8212,\n",
       " 'lucky': 4770,\n",
       " 'save': 6628,\n",
       " 'money': 5117,\n",
       " 'hee': 3806,\n",
       " 'finished': 3220,\n",
       " 'hi': 3846,\n",
       " 'babe': 1342,\n",
       " 'im': 4058,\n",
       " 'wanna': 8243,\n",
       " 'something': 7049,\n",
       " 'xx': 8552,\n",
       " 'performed': 5771,\n",
       " 'waiting': 8222,\n",
       " 'machan': 4812,\n",
       " 'once': 5529,\n",
       " 'thats': 7624,\n",
       " 'cool': 2259,\n",
       " 'gentleman': 3494,\n",
       " 'dignity': 2614,\n",
       " 'respect': 6426,\n",
       " 'peoples': 5763,\n",
       " 'very': 8130,\n",
       " 'much': 5186,\n",
       " 'shy': 6872,\n",
       " 'pa': 5649,\n",
       " 'operate': 5555,\n",
       " 'after': 963,\n",
       " 'same': 6598,\n",
       " 'looking': 4711,\n",
       " 'job': 4303,\n",
       " 'ta': 7473,\n",
       " 'earn': 2824,\n",
       " 'ah': 984,\n",
       " 'stop': 7266,\n",
       " 'urgnt': 8058,\n",
       " 'real': 6271,\n",
       " 'yo': 8604,\n",
       " 'tickets': 7709,\n",
       " 'one': 5531,\n",
       " 'jacket': 4246,\n",
       " 'used': 8070,\n",
       " 'multis': 5195,\n",
       " 'started': 7213,\n",
       " 'requests': 6407,\n",
       " 'came': 1834,\n",
       " 'bed': 1455,\n",
       " 'coins': 2126,\n",
       " 'factory': 3094,\n",
       " 'gotta': 3600,\n",
       " 'nitros': 5362,\n",
       " 'ela': 2878,\n",
       " 'kano': 4375,\n",
       " 'il': 4053,\n",
       " 'download': 2738,\n",
       " 'wen': 8333,\n",
       " 'stand': 7201,\n",
       " 'close': 2084,\n",
       " 'another': 1106,\n",
       " 'night': 5346,\n",
       " 'spent': 7132,\n",
       " 'late': 4522,\n",
       " 'afternoon': 965,\n",
       " 'casualty': 1897,\n",
       " 'means': 4946,\n",
       " 'haven': 3771,\n",
       " 'any': 1120,\n",
       " 'stuff42moro': 7321,\n",
       " 'includes': 4095,\n",
       " 'sheets': 6797,\n",
       " 'smile': 6990,\n",
       " 'pleasure': 5882,\n",
       " 'trouble': 7880,\n",
       " 'pours': 5984,\n",
       " 'rain': 6216,\n",
       " 'sum1': 7379,\n",
       " 'hurts': 3998,\n",
       " 'becoz': 1453,\n",
       " 'someone': 7043,\n",
       " 'loves': 4748,\n",
       " 'smiling': 6994,\n",
       " 'service': 6746,\n",
       " 'representative': 6404,\n",
       " '0800': 53,\n",
       " '169': 366,\n",
       " '6031': 647,\n",
       " 'between': 1507,\n",
       " '10am': 307,\n",
       " '9pm': 835,\n",
       " 'guaranteed': 3666,\n",
       " '5000': 609,\n",
       " 'havent': 3772,\n",
       " 'planning': 5866,\n",
       " 'buy': 1783,\n",
       " 'lido': 4600,\n",
       " '530': 627,\n",
       " 'show': 6853,\n",
       " 'collected': 2135,\n",
       " 'simply': 6899,\n",
       " 'password': 5718,\n",
       " 'mix': 5070,\n",
       " '85069': 770,\n",
       " 'verify': 8126,\n",
       " 'usher': 8076,\n",
       " 'britney': 1712,\n",
       " 'fml': 3282,\n",
       " 'telugu': 7565,\n",
       " 'movie': 5157,\n",
       " 'abt': 867,\n",
       " 'loads': 4675,\n",
       " 'loans': 4677,\n",
       " 'wk': 8443,\n",
       " 'hols': 3899,\n",
       " 'run': 6555,\n",
       " 'forgot': 3321,\n",
       " 'hairdressers': 3708,\n",
       " 'appointment': 1159,\n",
       " 'four': 3339,\n",
       " 'shower': 6855,\n",
       " 'beforehand': 1467,\n",
       " 'cause': 1904,\n",
       " 'prob': 6078,\n",
       " 'ham': 3717,\n",
       " 'nothing': 5410,\n",
       " 'else': 2892,\n",
       " 'okay': 5505,\n",
       " 'price': 6054,\n",
       " 'long': 4703,\n",
       " 'legal': 4569,\n",
       " 'them': 7636,\n",
       " 'ave': 1307,\n",
       " 'ams': 1075,\n",
       " 'gone': 3572,\n",
       " '4the': 597,\n",
       " 'driving': 2769,\n",
       " 'test': 7589,\n",
       " 'yet': 8595,\n",
       " 'mean': 4942,\n",
       " 'guess': 3672,\n",
       " 'gave': 3470,\n",
       " 'boston': 1629,\n",
       " 'men': 4979,\n",
       " 'changed': 1945,\n",
       " 'search': 6677,\n",
       " 'location': 4680,\n",
       " 'nyc': 5451,\n",
       " 'cuz': 2410,\n",
       " 'signin': 6887,\n",
       " 'page': 5656,\n",
       " 'says': 6636,\n",
       " 'umma': 7970,\n",
       " 'life': 4603,\n",
       " 'vava': 8112,\n",
       " 'lot': 4727,\n",
       " 'dear': 2471,\n",
       " 'wishes': 8427,\n",
       " 'birthday': 1542,\n",
       " 'making': 4852,\n",
       " 'truly': 7889,\n",
       " 'memorable': 4976,\n",
       " 'aight': 994,\n",
       " 'hit': 3866,\n",
       " 'would': 8504,\n",
       " 'ip': 4188,\n",
       " 'address': 922,\n",
       " 'considering': 2227,\n",
       " 'computer': 2190,\n",
       " 'isn': 4213,\n",
       " 'minecraft': 5030,\n",
       " 'server': 6745,\n",
       " 'grumpy': 3660,\n",
       " 'old': 5517,\n",
       " 'people': 5762,\n",
       " 'better': 1504,\n",
       " 'lying': 4790,\n",
       " 'jokes': 4316,\n",
       " 'worry': 8494,\n",
       " 'busy': 1777,\n",
       " 'plural': 5891,\n",
       " 'noun': 5417,\n",
       " 'research': 6412,\n",
       " 'cos': 2276,\n",
       " 'things': 7659,\n",
       " 'scared': 6642,\n",
       " 'mah': 4835,\n",
       " 'loud': 4735,\n",
       " 'gent': 3492,\n",
       " 'contact': 2232,\n",
       " 'last': 4519,\n",
       " 'weekends': 8316,\n",
       " 'draw': 2752,\n",
       " 'shows': 6861,\n",
       " '09064012160': 243,\n",
       " 'k52': 4358,\n",
       " '12hrs': 333,\n",
       " '150ppm': 355,\n",
       " 'wa': 8207,\n",
       " 'openin': 5552,\n",
       " 'sentence': 6734,\n",
       " 'formal': 3325,\n",
       " 'anyway': 1132,\n",
       " 'juz': 4357,\n",
       " 'tt': 7904,\n",
       " 'eatin': 2837,\n",
       " 'puttin': 6171,\n",
       " 'weight': 8321,\n",
       " 'haha': 3702,\n",
       " 'anythin': 1128,\n",
       " 'happened': 3738,\n",
       " 'entered': 2939,\n",
       " 'cabin': 1801,\n",
       " 'boss': 1628,\n",
       " 'felt': 3167,\n",
       " 'askd': 1235,\n",
       " 'invited': 4181,\n",
       " 'apartment': 1137,\n",
       " 'went': 8336,\n",
       " 'specially': 7118,\n",
       " 'holiday': 3896,\n",
       " 'flights': 3258,\n",
       " 'inc': 4089,\n",
       " 'operator': 5556,\n",
       " '0871277810910p': 129,\n",
       " 'min': 5023,\n",
       " 'goodo': 3585,\n",
       " 'must': 5214,\n",
       " 'friday': 3376,\n",
       " 'potato': 5976,\n",
       " 'ratio': 6245,\n",
       " 'tortilla': 7814,\n",
       " 'needed': 5293,\n",
       " 'hmm': 3878,\n",
       " 'uncle': 7979,\n",
       " 'informed': 4125,\n",
       " 'paying': 5739,\n",
       " 'school': 6648,\n",
       " 'directly': 2630,\n",
       " 'food': 3298,\n",
       " 'private': 6070,\n",
       " '2004': 401,\n",
       " 'account': 889,\n",
       " 'statement': 7221,\n",
       " '07742676969': 32,\n",
       " '786': 709,\n",
       " 'unredeemed': 8023,\n",
       " 'points': 5921,\n",
       " '08719180248': 175,\n",
       " 'identifier': 4034,\n",
       " '45239': 570,\n",
       " 'expires': 3065,\n",
       " '2000': 399,\n",
       " 'caller': 1821,\n",
       " '03': 15,\n",
       " 'landline': 4499,\n",
       " '09064019788': 249,\n",
       " 'box42wr29c': 1655,\n",
       " 'apples': 1154,\n",
       " 'pairs': 5664,\n",
       " 'malarky': 4854,\n",
       " 'todays': 7764,\n",
       " 'voda': 8176,\n",
       " 'numbers': 5437,\n",
       " 'ending': 2915,\n",
       " '7548': 701,\n",
       " '350': 506,\n",
       " 'award': 1319,\n",
       " 'match': 4906,\n",
       " '08712300220': 111,\n",
       " 'quoting': 6204,\n",
       " '4041': 543,\n",
       " 'standard': 7202,\n",
       " 'rates': 6243,\n",
       " 'app': 1147,\n",
       " 'sao': 6607,\n",
       " 'mu': 5184,\n",
       " 'ìï': 8661,\n",
       " 'predict': 6016,\n",
       " 'buying': 1786,\n",
       " 'yetunde': 8597,\n",
       " 'hasn': 3759,\n",
       " 'sent': 6733,\n",
       " 'bother': 1632,\n",
       " 'sending': 6725,\n",
       " 'involve': 4185,\n",
       " 'shouldn': 6848,\n",
       " 'imposed': 4077,\n",
       " 'apologise': 1144,\n",
       " 'girl': 3526,\n",
       " 'del': 2511,\n",
       " 'bak': 1364,\n",
       " 'sum': 7378,\n",
       " 'lucyxx': 4773,\n",
       " 'tmorrow': 7749,\n",
       " 'accomodate': 885,\n",
       " 'answer': 1109,\n",
       " 'sunshine': 7395,\n",
       " 'quiz': 6200,\n",
       " 'top': 7805,\n",
       " 'sony': 7063,\n",
       " 'dvd': 2812,\n",
       " 'player': 5872,\n",
       " 'country': 2296,\n",
       " 'algarve': 1022,\n",
       " 'ansr': 1108,\n",
       " '82277': 744,\n",
       " 'sp': 7099,\n",
       " 'tyrone': 7950,\n",
       " 'laid': 4491,\n",
       " 'dogging': 2696,\n",
       " 'locations': 4681,\n",
       " 'direct': 2629,\n",
       " 'join': 4311,\n",
       " 'largest': 4516,\n",
       " 'bt': 1738,\n",
       " 'txting': 7939,\n",
       " 'gravel': 3628,\n",
       " '69888': 675,\n",
       " 'nt': 5427,\n",
       " 'ec2a': 2840,\n",
       " '31p': 498,\n",
       " 'haf': 3701,\n",
       " 'msn': 5175,\n",
       " 'yijue': 8601,\n",
       " 'hotmail': 3942,\n",
       " 'him': 3857,\n",
       " 'rooms': 6518,\n",
       " 'befor': 1465,\n",
       " 'activities': 910,\n",
       " 'msgs': 5174,\n",
       " 'chat': 1966,\n",
       " 'svc': 7430,\n",
       " 'hardcore': 3748,\n",
       " 'services': 6747,\n",
       " '69988': 679,\n",
       " 'age': 973,\n",
       " 'yr': 8627,\n",
       " 'lazy': 4542,\n",
       " 'type': 7947,\n",
       " 'lect': 4563,\n",
       " 'pouch': 5979,\n",
       " 'sir': 6914,\n",
       " 'mail': 4840,\n",
       " 'swt': 7459,\n",
       " 'nver': 5445,\n",
       " 'tired': 7729,\n",
       " 'little': 4660,\n",
       " 'lovable': 4739,\n",
       " 'persons': 5789,\n",
       " 'coz': 2309,\n",
       " 'somtimes': 7058,\n",
       " 'those': 7677,\n",
       " 'occupy': 5469,\n",
       " 'biggest': 1524,\n",
       " 'their': 7633,\n",
       " 'hearts': 3799,\n",
       " 'gud': 3668,\n",
       " 'ni8': 5336,\n",
       " 'open': 5549,\n",
       " 'ya': 8565,\n",
       " 'dot': 2729,\n",
       " 'whats': 8357,\n",
       " 'staff': 7193,\n",
       " 'taking': 7493,\n",
       " 'replied': 6397,\n",
       " 'randy': 6236,\n",
       " 'sexy': 6763,\n",
       " 'female': 3168,\n",
       " 'local': 4679,\n",
       " 'luv': 4781,\n",
       " 'netcollex': 5312,\n",
       " 'ltd': 4764,\n",
       " '08700621170150p': 81,\n",
       " 'ummma': 7972,\n",
       " 'begin': 1471,\n",
       " 'qatar': 6177,\n",
       " 'pray': 6011,\n",
       " 'hard': 3747,\n",
       " 'deleted': 2515,\n",
       " 'sindu': 6904,\n",
       " 'birla': 1538,\n",
       " 'soft': 7029,\n",
       " 'wine': 8412,\n",
       " 'flowing': 3273,\n",
       " 'nevering': 5322,\n",
       " 'thk': 7670,\n",
       " 'plaza': 5877,\n",
       " 'typical': 7949,\n",
       " 'everywhere': 3016,\n",
       " 'dirt': 2633,\n",
       " 'floor': 3267,\n",
       " 'windows': 8409,\n",
       " 'shirt': 6816,\n",
       " 'sometimes': 7051,\n",
       " 'mouth': 5153,\n",
       " 'dream': 2755,\n",
       " 'without': 8437,\n",
       " 'chores': 2037,\n",
       " 'joy': 4329,\n",
       " 'lots': 4729,\n",
       " 'tv': 7922,\n",
       " 'exist': 3050,\n",
       " ...}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a586f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>ó_</th>\n",
       "      <th>û_</th>\n",
       "      <th>û_thanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0      0    0       0             0     0     0            0            0   \n",
       "1      0    0       0             0     0     0            0            0   \n",
       "2      0    0       0             0     0     0            0            0   \n",
       "3      0    0       0             0     0     0            0            0   \n",
       "4      0    0       0             0     0     0            0            0   \n",
       "...   ..  ...     ...           ...   ...   ...          ...          ...   \n",
       "5567   0    0       0             0     0     0            0            0   \n",
       "5568   0    0       0             0     0     0            0            0   \n",
       "5569   0    0       0             0     0     0            0            0   \n",
       "5570   0    0       0             0     0     0            0            0   \n",
       "5571   0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  ó_  û_  û_thanks  ûªm  ûªt  ûªve  ûï  ûïharry  ûò  \\\n",
       "0              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "1              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "2              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "3              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "4              0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "...          ...  ..  ...  ..  ..       ...  ...  ...   ...  ..      ...  ..   \n",
       "5567           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5568           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5569           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5570           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "5571           0   0  ...   0   0         0    0    0     0   0        0   0   \n",
       "\n",
       "      ûówell  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "5567       0  \n",
       "5568       0  \n",
       "5569       0  \n",
       "5570       0  \n",
       "5571       0  \n",
       "\n",
       "[5572 rows x 8672 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = pd.DataFrame(X_bag_of_words.todense(), columns = cv.get_feature_names())\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d36e22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bag_of_words, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc2ab7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.73%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3859    12\n",
      "spam          0   586\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3859\n",
      "        spam       1.00      0.98      0.99       598\n",
      "\n",
      "    accuracy                           1.00      4457\n",
      "   macro avg       1.00      0.99      0.99      4457\n",
      "weighted avg       1.00      1.00      1.00      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b30f81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.39%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        964    16\n",
      "spam         2   133\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.99      0.89      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10ca49",
   "metadata": {},
   "source": [
    "#### Decision Tree - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a763f92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = dtc.predict(X_train)\n",
    "test['predicted'] = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baa546b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.25%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3829   271\n",
      "spam         30   327\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.99      0.96      3859\n",
      "        spam       0.92      0.55      0.68       598\n",
      "\n",
      "    accuracy                           0.93      4457\n",
      "   macro avg       0.92      0.77      0.82      4457\n",
      "weighted avg       0.93      0.93      0.92      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebeea8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.27%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    69\n",
      "spam         6    80\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.99      0.96       966\n",
      "        spam       0.93      0.54      0.68       149\n",
      "\n",
      "    accuracy                           0.93      1115\n",
      "   macro avg       0.93      0.77      0.82      1115\n",
      "weighted avg       0.93      0.93      0.92      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7574076d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Depth = 3\n",
      "Accuracy: 94.50%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3847   233\n",
      "spam         12   365\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      1.00      0.97      3859\n",
      "        spam       0.97      0.61      0.75       598\n",
      "\n",
      "    accuracy                           0.95      4457\n",
      "   macro avg       0.96      0.80      0.86      4457\n",
      "weighted avg       0.95      0.95      0.94      4457\n",
      "\n",
      "Decision Tree Depth = 3\n",
      "Accuracy: 93.90%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        964    66\n",
      "spam         2    83\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      1.00      0.97       966\n",
      "        spam       0.98      0.56      0.71       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.96      0.78      0.84      1115\n",
      "weighted avg       0.94      0.94      0.93      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 4\n",
      "Accuracy: 95.47%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3801   144\n",
      "spam         58   454\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97      3859\n",
      "        spam       0.89      0.76      0.82       598\n",
      "\n",
      "    accuracy                           0.95      4457\n",
      "   macro avg       0.93      0.87      0.90      4457\n",
      "weighted avg       0.95      0.95      0.95      4457\n",
      "\n",
      "Decision Tree Depth = 4\n",
      "Accuracy: 93.99%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        944    45\n",
      "spam        22   104\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.98      0.97       966\n",
      "        spam       0.83      0.70      0.76       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.89      0.84      0.86      1115\n",
      "weighted avg       0.94      0.94      0.94      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 5\n",
      "Accuracy: 96.16%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3821   133\n",
      "spam         38   465\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      3859\n",
      "        spam       0.92      0.78      0.84       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.95      0.88      0.91      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n",
      "Decision Tree Depth = 5\n",
      "Accuracy: 95.43%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    45\n",
      "spam         6   104\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.97       966\n",
      "        spam       0.95      0.70      0.80       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.95      0.85      0.89      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 6\n",
      "Accuracy: 96.77%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3831   116\n",
      "spam         28   482\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      3859\n",
      "        spam       0.95      0.81      0.87       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.96      0.90      0.93      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Decision Tree Depth = 6\n",
      "Accuracy: 95.25%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        958    45\n",
      "spam         8   104\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.97       966\n",
      "        spam       0.93      0.70      0.80       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.94      0.84      0.89      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 7\n",
      "Accuracy: 97.15%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3837   105\n",
      "spam         22   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      3859\n",
      "        spam       0.96      0.82      0.89       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.97      0.91      0.93      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Decision Tree Depth = 7\n",
      "Accuracy: 95.61%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        958    41\n",
      "spam         8   108\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       966\n",
      "        spam       0.93      0.72      0.82       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.94      0.86      0.90      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 8\n",
      "Accuracy: 97.37%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3838    96\n",
      "spam         21   502\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.96      0.84      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.97      0.92      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Decision Tree Depth = 8\n",
      "Accuracy: 95.87%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        958    38\n",
      "spam         8   111\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       966\n",
      "        spam       0.93      0.74      0.83       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.95      0.87      0.90      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 9\n",
      "Accuracy: 97.62%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3859   106\n",
      "spam          0   492\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.99      0.91      0.94      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "Decision Tree Depth = 9\n",
      "Accuracy: 95.70%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    42\n",
      "spam         6   107\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       966\n",
      "        spam       0.95      0.72      0.82       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.95      0.86      0.90      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 10\n",
      "Accuracy: 97.82%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3852    90\n",
      "spam          7   508\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      3859\n",
      "        spam       0.99      0.85      0.91       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.92      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "Decision Tree Depth = 10\n",
      "Accuracy: 96.05%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        958    36\n",
      "spam         8   113\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       966\n",
      "        spam       0.93      0.76      0.84       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.95      0.88      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,11):\n",
    "    dtc = DecisionTreeClassifier(max_depth = i).fit(X_train, y_train)\n",
    "\n",
    "    train['predicted'] = dtc.predict(X_train)\n",
    "    test['predicted'] = dtc.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Depth =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "    print('---')\n",
    "    print('Train Data - Confusion Matrix')\n",
    "    print(pd.crosstab(train.predicted, train.actual))\n",
    "    print('---')\n",
    "    print(classification_report(train.actual, train.predicted))\n",
    "    \n",
    "    print('Decision Tree Depth =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "    print('---')\n",
    "    print('Test Data - Confusion Matrix')\n",
    "    print(pd.crosstab(test.predicted, test.actual))\n",
    "    print('---')\n",
    "    print(classification_report(test.actual, test.predicted))\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c1824",
   "metadata": {},
   "source": [
    "#### Decision Tree - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0bd827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_bag_of_words, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = dtc.predict(X_train)\n",
    "test['predicted'] = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48771102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.80%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3859     9\n",
      "spam          0   589\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3859\n",
      "        spam       1.00      0.98      0.99       598\n",
      "\n",
      "    accuracy                           1.00      4457\n",
      "   macro avg       1.00      0.99      1.00      4457\n",
      "weighted avg       1.00      1.00      1.00      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51a6742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.76%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        965    24\n",
      "spam         1   125\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.99      0.84      0.91       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d1bce5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Depth = 3\n",
      "Accuracy: 94.23%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3790   188\n",
      "spam         69   410\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.98      0.97      3859\n",
      "        spam       0.86      0.69      0.76       598\n",
      "\n",
      "    accuracy                           0.94      4457\n",
      "   macro avg       0.90      0.83      0.86      4457\n",
      "weighted avg       0.94      0.94      0.94      4457\n",
      "\n",
      "Decision Tree Depth = 3\n",
      "Accuracy: 93.99%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        947    48\n",
      "spam        19   101\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.98      0.97       966\n",
      "        spam       0.84      0.68      0.75       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.90      0.83      0.86      1115\n",
      "weighted avg       0.94      0.94      0.94      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 4\n",
      "Accuracy: 95.04%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3794   156\n",
      "spam         65   442\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97      3859\n",
      "        spam       0.87      0.74      0.80       598\n",
      "\n",
      "    accuracy                           0.95      4457\n",
      "   macro avg       0.92      0.86      0.89      4457\n",
      "weighted avg       0.95      0.95      0.95      4457\n",
      "\n",
      "Decision Tree Depth = 4\n",
      "Accuracy: 94.53%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        947    42\n",
      "spam        19   107\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97       966\n",
      "        spam       0.85      0.72      0.78       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.90      0.85      0.87      1115\n",
      "weighted avg       0.94      0.95      0.94      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 5\n",
      "Accuracy: 95.74%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3807   138\n",
      "spam         52   460\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      3859\n",
      "        spam       0.90      0.77      0.83       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.93      0.88      0.90      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n",
      "Decision Tree Depth = 5\n",
      "Accuracy: 95.25%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        949    36\n",
      "spam        17   113\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97       966\n",
      "        spam       0.87      0.76      0.81       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.92      0.87      0.89      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 6\n",
      "Accuracy: 96.23%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3814   123\n",
      "spam         45   475\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      3859\n",
      "        spam       0.91      0.79      0.85       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.94      0.89      0.91      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n",
      "Decision Tree Depth = 6\n",
      "Accuracy: 95.34%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        950    36\n",
      "spam        16   113\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97       966\n",
      "        spam       0.88      0.76      0.81       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.92      0.87      0.89      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 7\n",
      "Accuracy: 96.39%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3823   125\n",
      "spam         36   473\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      3859\n",
      "        spam       0.93      0.79      0.85       598\n",
      "\n",
      "    accuracy                           0.96      4457\n",
      "   macro avg       0.95      0.89      0.92      4457\n",
      "weighted avg       0.96      0.96      0.96      4457\n",
      "\n",
      "Decision Tree Depth = 7\n",
      "Accuracy: 95.43%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        950    35\n",
      "spam        16   114\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.98      0.97       966\n",
      "        spam       0.88      0.77      0.82       149\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.92      0.87      0.90      1115\n",
      "weighted avg       0.95      0.95      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 8\n",
      "Accuracy: 97.02%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3824    98\n",
      "spam         35   500\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.84      0.88       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.91      0.93      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Decision Tree Depth = 8\n",
      "Accuracy: 95.61%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        950    33\n",
      "spam        16   116\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.98      0.97       966\n",
      "        spam       0.88      0.78      0.83       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.92      0.88      0.90      1115\n",
      "weighted avg       0.95      0.96      0.95      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 9\n",
      "Accuracy: 97.40%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3830    87\n",
      "spam         29   511\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99      3859\n",
      "        spam       0.95      0.85      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.96      0.92      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Decision Tree Depth = 9\n",
      "Accuracy: 96.14%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        952    29\n",
      "spam        14   120\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.90      0.81      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.93      0.90      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Decision Tree Depth = 10\n",
      "Accuracy: 97.62%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3828    75\n",
      "spam         31   523\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99      3859\n",
      "        spam       0.94      0.87      0.91       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.96      0.93      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "Decision Tree Depth = 10\n",
      "Accuracy: 96.05%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        950    28\n",
      "spam        16   121\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.98      0.98       966\n",
      "        spam       0.88      0.81      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.93      0.90      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,11):\n",
    "    dtc = DecisionTreeClassifier(max_depth = i).fit(X_train, y_train)\n",
    "\n",
    "    train['predicted'] = dtc.predict(X_train)\n",
    "    test['predicted'] = dtc.predict(X_test)\n",
    "    \n",
    "    print('Decision Tree Depth =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "    print('---')\n",
    "    print('Train Data - Confusion Matrix')\n",
    "    print(pd.crosstab(train.predicted, train.actual))\n",
    "    print('---')\n",
    "    print(classification_report(train.actual, train.predicted))\n",
    "    \n",
    "    print('Decision Tree Depth =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "    print('---')\n",
    "    print('Test Data - Confusion Matrix')\n",
    "    print(pd.crosstab(test.predicted, test.actual))\n",
    "    print('---')\n",
    "    print(classification_report(test.actual, test.predicted))\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed3d05",
   "metadata": {},
   "source": [
    "#### Random Forest - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68cba381",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = rf.predict(X_train)\n",
    "test['predicted'] = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2501cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.58%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3859   598\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      1.00      0.93      3859\n",
      "        spam       0.00      0.00      0.00       598\n",
      "\n",
      "    accuracy                           0.87      4457\n",
      "   macro avg       0.43      0.50      0.46      4457\n",
      "weighted avg       0.75      0.87      0.80      4457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53e8c36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.64%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        966   149\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      1.00      0.93       966\n",
      "        spam       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.87      1115\n",
      "   macro avg       0.43      0.50      0.46      1115\n",
      "weighted avg       0.75      0.87      0.80      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae0e92",
   "metadata": {},
   "source": [
    "#### Random Forest - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86f88bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bag_of_words, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = rf.predict(X_train)\n",
    "test['predicted'] = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1bc0d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.58%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3859   598\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      1.00      0.93      3859\n",
      "        spam       0.00      0.00      0.00       598\n",
      "\n",
      "    accuracy                           0.87      4457\n",
      "   macro avg       0.43      0.50      0.46      4457\n",
      "weighted avg       0.75      0.87      0.80      4457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c07818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.64%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        966   149\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      1.00      0.93       966\n",
      "        spam       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.87      1115\n",
      "   macro avg       0.43      0.50      0.46      1115\n",
      "weighted avg       0.75      0.87      0.80      1115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davidrodriguez/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b62d06",
   "metadata": {},
   "source": [
    "#### KNN - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdc646d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 2).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = dtc.predict(X_train)\n",
    "test['predicted'] = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0275cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.44%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96d08999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.58%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e76f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of K = 3\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 3\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 4\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 4\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 5\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 5\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 6\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 6\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 7\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 7\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 8\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 8\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 9\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 9\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 10\n",
      "Accuracy: 97.44%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3850   105\n",
      "spam          9   493\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       0.98      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 10\n",
      "Accuracy: 97.58%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        960    21\n",
      "spam         6   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       966\n",
      "        spam       0.96      0.86      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i).fit(X_train, y_train)\n",
    "\n",
    "    train['predicted'] = dtc.predict(X_train)\n",
    "    test['predicted'] = dtc.predict(X_test)\n",
    "    \n",
    "    print('Value of K =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "    print('---')\n",
    "    print('Train Data - Confusion Matrix')\n",
    "    print(pd.crosstab(train.predicted, train.actual))\n",
    "    print('---')\n",
    "    print(classification_report(train.actual, train.predicted))\n",
    "    \n",
    "    print('Value of K =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "    print('---')\n",
    "    print('Test Data - Confusion Matrix')\n",
    "    print(pd.crosstab(test.predicted, test.actual))\n",
    "    print('---')\n",
    "    print(classification_report(test.actual, test.predicted))\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63311d6b",
   "metadata": {},
   "source": [
    "#### KNN - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1442d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bag_of_words, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 2).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = dtc.predict(X_train)\n",
    "test['predicted'] = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d59b48fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.31%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9c75d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.31%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80790b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of K = 3\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 3\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 4\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 4\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 5\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 5\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 6\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 6\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 7\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 7\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 8\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 8\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 9\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 9\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n",
      "Value of K = 10\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Train Data - Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3817    78\n",
      "spam         42   520\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.98      3859\n",
      "        spam       0.93      0.87      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.95      0.93      0.94      4457\n",
      "weighted avg       0.97      0.97      0.97      4457\n",
      "\n",
      "Value of K = 10\n",
      "Accuracy: 97.31%\n",
      "---\n",
      "Test Data - Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        961    25\n",
      "spam         5   124\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       966\n",
      "        spam       0.96      0.83      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.97      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i).fit(X_train, y_train)\n",
    "\n",
    "    train['predicted'] = dtc.predict(X_train)\n",
    "    test['predicted'] = dtc.predict(X_test)\n",
    "    \n",
    "    print('Value of K =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "    print('---')\n",
    "    print('Train Data - Confusion Matrix')\n",
    "    print(pd.crosstab(train.predicted, train.actual))\n",
    "    print('---')\n",
    "    print(classification_report(train.actual, train.predicted))\n",
    "    \n",
    "    print('Value of K =', i)\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "    print('---')\n",
    "    print('Test Data - Confusion Matrix')\n",
    "    print(pd.crosstab(test.predicted, test.actual))\n",
    "    print('---')\n",
    "    print(classification_report(test.actual, test.predicted))\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dfd260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f7f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf9857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12934e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
